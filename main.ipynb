{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conectando à DataBase\n",
    "\n",
    "### Importando bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import joblib\n",
    "import json\n",
    "import numpy as np\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configurações da DataBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_CONFIG = {\n",
    "    'dbname': 'ml_models_comparations',\n",
    "    'user': 'postgres',\n",
    "    'password': 'zzrispudb',\n",
    "    'host': 'localhost',\n",
    "    'port': '5432'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função para salvar o modelo na DataBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_to_db(model, name, model_type, hyperparameters):\n",
    "    model_bytes = BytesIO()\n",
    "    joblib.dump(model, model_bytes)\n",
    "    model_bytes.seek(0)\n",
    "\n",
    "    conn = psycopg2.connect(**DB_CONFIG, options='-c client_encoding=utf8')\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    try:\n",
    "        hyperparameters = json.dumps(hyperparameters, ensure_ascii=False)\n",
    "    except TypeError as e:\n",
    "        print(f'Error: {e}')\n",
    "        hyperparameters = \"{}\"\n",
    "\n",
    "    cur.execute(\n",
    "        \"INSERT INTO models (name, type, hyperparameters) VALUES (%s, %s, %s) RETURNING id\",\n",
    "        (name, model_type, json.dumps(hyperparameters))\n",
    "    )\n",
    "\n",
    "    model_id = cur.fetchone()[0]\n",
    "    conn.commit()\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "    \n",
    "    return model_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função para salvar o preprocessamento na DataBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_preprocessing_to_db(sampling_strategy, normalized, split_method, test_size):\n",
    "    conn = psycopg2.connect(**DB_CONFIG, options='-c client_encoding=utf8')\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    cur.execute(\n",
    "        \"INSERT INTO preprocessing (sampling_strategy, normalized, split_method, test_size) VALUES (%s, %s, %s, %s) RETURNING id;\",\n",
    "        (sampling_strategy, normalized, split_method, test_size)\n",
    "    )\n",
    "\n",
    "    preprocessing_id = cur.fetchone()[0]\n",
    "    conn.commit()\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "    \n",
    "    return preprocessing_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função para salvar as métricas na DataBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_metrics_to_db(result_id, metrics):\n",
    "    conn = psycopg2.connect(**DB_CONFIG, options='-c client_encoding=utf8')\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    for metric_name, metric_value in metrics.items():\n",
    "        cur.execute(\n",
    "            \"INSERT INTO metrics (result_id, metric_name, metric_value) VALUES (%s, %s, %s);\",\n",
    "            (result_id, metric_name, float(metric_value))\n",
    "        )\n",
    "\n",
    "    conn.commit()\n",
    "    cur.close()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função geral para salvar os resultados na DataBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(model, name, model_type, hyperparameters, sampling_strategy, normalized, split_method, test_size, dataset, train_size, metrics):\n",
    "    model_id = save_model_to_db(model, name, model_type, hyperparameters)\n",
    "    preprocessing_id = save_preprocessing_to_db(sampling_strategy, normalized, split_method, test_size)\n",
    "\n",
    "    conn = psycopg2.connect(**DB_CONFIG, options='-c client_encoding=utf8')\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    cur.execute(\n",
    "        \"INSERT INTO results (model_id, preprocessing_id, dataset, train_size, test_size) VALUES (%s, %s, %s, %s, %s) RETURNING id;\",\n",
    "        (model_id, preprocessing_id, dataset, train_size, test_size)\n",
    "    )\n",
    "\n",
    "    result_id = cur.fetchone()[0]\n",
    "    conn.commit()\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "\n",
    "    save_metrics_to_db(result_id, metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estrutura do Pipeline\n",
    "### Importando bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedGroupKFold, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pré-processamento de dados\n",
    "\n",
    "Amostragem e separação em treino/validação/teste.\n",
    "\n",
    "> Amostragem:\n",
    "> * Urdersampling (reduz classes majoritárias)\n",
    "> * Oversampling (reduz classes minoritárias)\n",
    "> * Stratified Sampling (mantém proporções das classes)\n",
    "\n",
    "> Divisão de dados:\n",
    "> * Hold-out: (treino/validação/teste fix, ex: 70/20/10)\n",
    "> * Cross-Validation (validação cruzada com K-Folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(X, y, problem_type='classification', sampling_strategy='none', split_method='holdout', test_size=0.2, folds=5, random_state=42):\n",
    "    # Converter para DataFrame se for numpy array\n",
    "    if not isinstance(X, pd.DataFrame):\n",
    "        X = pd.DataFrame(X)\n",
    "\n",
    "    # Aplicar amostragem se necessário (só para classificação)\n",
    "    if sampling_strategy == 'undersampling':\n",
    "        X, y = RandomUnderSampler().fit_resample(X, y)\n",
    "    elif sampling_strategy == 'oversampling':\n",
    "        X, y = SMOTE().fit_resample(X, y)\n",
    "\n",
    "    # Dividir os dados em treino e teste\n",
    "    if split_method == 'holdout':\n",
    "        stratify = y if problem_type == 'classification' else None\n",
    "        return train_test_split(X, y, test_size=test_size, stratify=stratify, random_state=random_state)\n",
    "    elif split_method == 'cross-validation':\n",
    "        if problem_type == 'classification':\n",
    "            return StratifiedGroupKFold(n_splits=folds, shuffle=True, random_state=random_state).split(X, y, groups=X['subject'])\n",
    "        else:\n",
    "            return KFold(n_splits=folds, shuffle=True, random_state=random_state).split(X, y)\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregando DataSets\n",
    "\n",
    "> Classificação:\n",
    "> * Iris DataSet\n",
    "> * Breast Cancer Dataset\n",
    "\n",
    "> Regressão\n",
    "> * Boston Housing Dataset\n",
    "> * California Housing Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iris DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho do treino: 120 | Tamanho do teste: 30\n"
     ]
    }
   ],
   "source": [
    "# Iris DataSet\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris_ds = load_iris()\n",
    "X_iris, y_iris = iris_ds.data, iris_ds.target\n",
    "\n",
    "X_train_iris, X_test_iris, y_train_iris, y_test_iris = preprocess_data(X_iris, y_iris, sampling_strategy='oversampling', split_method='holdout')\n",
    "\n",
    "print(f\"Tamanho do treino: {len(X_train_iris)} | Tamanho do teste: {len(X_test_iris)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Breast Cancer DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho do treino: 339 | Tamanho do teste: 85\n"
     ]
    }
   ],
   "source": [
    "# Breast Cancer DataSet\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "bc_ds = load_breast_cancer()\n",
    "X_bc, y_bc = bc_ds.data, bc_ds.target\n",
    "\n",
    "X_train_bc, X_test_bc, y_train_bc, y_test_bc = preprocess_data(X_bc, y_bc, sampling_strategy='undersampling', split_method='holdout')\n",
    "print(f\"Tamanho do treino: {len(X_train_bc)} | Tamanho do teste: {len(X_test_bc)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boston Housing DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho do treino: 404 | Tamanho do teste: 102\n",
      "[1 1 0 0 1 0 1 1 0 1 0 1 1 0 1 0 1 1 1 1 0 0 1 0 0 1 0 0 0 0 0 0 0 1 1 0 0\n",
      " 0 1 0 0 1 1 0 1 0 0 0 1 0 1 0 1 1 1 0 0 1 0 1 1 1 0 1 0 1 1 0 0 1 1 0 1 0\n",
      " 0 0 0 1 0 1 0 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Boston Housing DataSet\n",
    "bh_ds = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/BostonHousing.csv')\n",
    "\n",
    "X_bh, y_bh = bh_ds.drop(columns=[\"medv\"]), bh_ds['medv']\n",
    "\n",
    "X_train_bh, X_test_bh, y_train_bh, y_test_bh = preprocess_data(X_bh, y_bh, problem_type='regression', sampling_strategy='none', split_method='holdout')\n",
    "print(f\"Tamanho do treino: {len(X_train_bh)} | Tamanho do teste: {len(X_test_bh)}\")\n",
    "print(y_test_bc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### California Housing DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho do treino: 16512 | Tamanho do teste: 4128\n"
     ]
    }
   ],
   "source": [
    "# California Housing DataSet\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "cali_ds = fetch_california_housing(as_frame=True)\n",
    "\n",
    "X_cali, y_cali = cali_ds.data, cali_ds.target\n",
    "\n",
    "X_train_cali, X_test_cali, y_train_cali, y_test_cali = preprocess_data(X_cali, y_cali, problem_type='regression', sampling_strategy='none', split_method='holdout')\n",
    "print(f\"Tamanho do treino: {len(X_train_cali)} | Tamanho do teste: {len(X_test_cali)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinando e Avaliando métricas dos modelos\n",
    "\n",
    "### Importando modelos de ML\n",
    "\n",
    "> Classificação:\n",
    "> * Random Forest Classifier\n",
    "> * Decision Tree Classifier\n",
    "\n",
    "> Regressão:\n",
    "> * Linear Regression\n",
    "> * Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importando métodos de métricas para ML\n",
    "\n",
    "> Classificação:\n",
    "> * Acurácia\n",
    "> * Precisão\n",
    "> * Recall\n",
    "> * F1-score\n",
    "> * ROC-AUC\n",
    "\n",
    "> Regressão:\n",
    "> * MSE\n",
    "> * RMSE\n",
    "> * MAE\n",
    "> * R²"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para classificação\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "# Para regressão\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construindo funções para treinar e avaliar modelos, e salvar resultados na DataBase\n",
    "#### Modelos de classificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para treinar e avaliar modelos de classificação\n",
    "def train_evaluate_saveToDB_classification(dataset_name, X_train, y_train, X_test, y_test, normalized=False):\n",
    "    models = {\n",
    "        'RandomForest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "        'DecisionTree': DecisionTreeClassifier(max_depth=5, random_state=42)\n",
    "    }\n",
    "\n",
    "    results = {}\n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        if len(np.unique(y_test)) == 2:\n",
    "            roc_auc = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n",
    "        else:\n",
    "            roc_auc = roc_auc_score(y_test, model.predict_proba(X_test), multi_class='ovo', average='weighted')\n",
    "\n",
    "        results[name] = {\n",
    "            'accuracy': accuracy_score(y_test, y_pred),\n",
    "            'precision': precision_score(y_test, y_pred, average='weighted'),\n",
    "            'recall': recall_score(y_test, y_pred, average='weighted'),\n",
    "            'f1': f1_score(y_test, y_pred, average='weighted'),\n",
    "            'roc_auc': roc_auc\n",
    "        }\n",
    "\n",
    "        save_results(model, name, 'classification', model.get_params(), 'oversampling', normalized, 'holdout', len(X_test), dataset_name, len(X_train), results[name])\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelos de regressão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para treinar e avaliar modelos de regressão\n",
    "def train_evaluate_saveToDB_regression(dataset_name, X_train, y_train, X_test, y_test, normalized=False):\n",
    "    models = {\n",
    "        'LinearRegression': LinearRegression(),\n",
    "        'DecisionTree': DecisionTreeRegressor()\n",
    "    }\n",
    "\n",
    "    results = {}\n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        results[name] = {\n",
    "            'mse': mean_squared_error(y_test, y_pred),\n",
    "            'mape': mean_absolute_percentage_error(y_test, y_pred),\n",
    "            'mae': mean_absolute_error(y_test, y_pred),\n",
    "            'r2': r2_score(y_test, y_pred)\n",
    "        }\n",
    "        \n",
    "        save_results(model, name, 'regression', model.get_params(), 'none', normalized, 'holdout', len(X_test), dataset_name, len(X_train), results[name])\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinando e avaliando diferentes modelos com diferentes DataSets, e salvando seus resultados na DataBase\n",
    "\n",
    "#### Iris Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris DataSet | Não normalizado\n",
      "            RandomForest  DecisionTree\n",
      "accuracy       0.900000      0.933333\n",
      "precision      0.902357      0.933333\n",
      "recall         0.900000      0.933333\n",
      "f1             0.899749      0.933333\n",
      "roc_auc        0.986667      0.950000\n",
      "\n",
      "Iris DataSet | Normalizado\n",
      "            RandomForest  DecisionTree\n",
      "accuracy       0.966667      0.933333\n",
      "precision      0.969697      0.933333\n",
      "recall         0.966667      0.933333\n",
      "f1             0.966583      0.933333\n",
      "roc_auc        0.986667      0.950000\n"
     ]
    }
   ],
   "source": [
    "iris_results_raw = train_evaluate_saveToDB_classification(\"Iris DataSet\", X_train_iris, y_train_iris, X_test_iris, y_test_iris)\n",
    "iris_results_normalized = train_evaluate_saveToDB_classification(\"Iris DataSet\", StandardScaler().fit_transform(X_train_iris), y_train_iris, StandardScaler().fit_transform(X_test_iris), y_test_iris, True)\n",
    "print(\"Iris DataSet | Não normalizado\\n\", pd.DataFrame.from_dict(iris_results_raw))\n",
    "print(\"\\nIris DataSet | Normalizado\\n\", pd.DataFrame.from_dict(iris_results_normalized))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Breast Cancer DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breast Cancer DataSet | Não normalizado\n",
      "            RandomForest  DecisionTree\n",
      "accuracy       0.917647      0.964706\n",
      "precision      0.917901      0.964973\n",
      "recall         0.917647      0.964706\n",
      "f1             0.917647      0.964706\n",
      "roc_auc        0.992248      0.955703\n",
      "\n",
      "Breast Cancer DataSet | Normalizado\n",
      "            RandomForest  DecisionTree\n",
      "accuracy       0.917647      0.952941\n",
      "precision      0.917901      0.953972\n",
      "recall         0.917647      0.952941\n",
      "f1             0.917647      0.952928\n",
      "roc_auc        0.991141      0.945183\n"
     ]
    }
   ],
   "source": [
    "bc_results_raw = train_evaluate_saveToDB_classification(\"Breast Cancer DataSet\", X_train_bc, y_train_bc, X_test_bc, y_test_bc)\n",
    "bc_results_normalized = train_evaluate_saveToDB_classification(\"Breast Cancer DataSet\", StandardScaler().fit_transform(X_train_bc), y_train_bc, StandardScaler().fit_transform(X_test_bc), y_test_bc, True)\n",
    "print(\"Breast Cancer DataSet | Não normalizado\\n\", pd.DataFrame.from_dict(bc_results_raw))\n",
    "print(\"\\nBreast Cancer DataSet | Normalizado\\n\", pd.DataFrame.from_dict(bc_results_normalized))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bonston Housing DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boston Housing DataSet | Não normalizado\n",
      "       LinearRegression  DecisionTree\n",
      "mse          24.291119     21.508922\n",
      "mape          0.168664      0.146610\n",
      "mae           3.189092      2.673529\n",
      "r2            0.668759      0.706698\n",
      "\n",
      "Boston Housing DataSet | Normalizado\n",
      "       LinearRegression  DecisionTree\n",
      "mse          27.406836     30.907843\n",
      "mape          0.207548      0.191986\n",
      "mae           3.852622      3.554902\n",
      "r2            0.626273      0.578532\n"
     ]
    }
   ],
   "source": [
    "bh_results_raw = train_evaluate_saveToDB_regression(\"Bonston Housing DataSet\", X_train_bh, y_train_bh, X_test_bh, y_test_bh)\n",
    "bh_results_normalized = train_evaluate_saveToDB_regression(\"Bonston Housing DataSet\", StandardScaler().fit_transform(X_train_bh), y_train_bh, StandardScaler().fit_transform(X_test_bh), y_test_bh, True)\n",
    "print(\"Boston Housing DataSet | Não normalizado\\n\", pd.DataFrame.from_dict(bh_results_raw))\n",
    "print(\"\\nBoston Housing DataSet | Normalizado\\n\", pd.DataFrame.from_dict(bh_results_normalized))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### California Housing DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "California Housing DataSet | Não normalizado\n",
      "       LinearRegression  DecisionTree\n",
      "mse           0.555892      0.484998\n",
      "mape          0.319522      0.244687\n",
      "mae           0.533200      0.450528\n",
      "r2            0.575788      0.629888\n",
      "\n",
      "California Housing DataSet | Normalizado\n",
      "       LinearRegression  DecisionTree\n",
      "mse           0.538865      1.219295\n",
      "mape          0.321809      0.419667\n",
      "mae           0.535317      0.744401\n",
      "r2            0.588781      0.069531\n"
     ]
    }
   ],
   "source": [
    "cali_results_raw = train_evaluate_saveToDB_regression(\"California Housing DataSet\", X_train_cali, y_train_cali, X_test_cali, y_test_cali)\n",
    "cali_results_normalized = train_evaluate_saveToDB_regression(\"California Housing DataSet\", StandardScaler().fit_transform(X_train_cali), y_train_cali, StandardScaler().fit_transform(X_test_cali), y_test_cali, True)\n",
    "print(\"California Housing DataSet | Não normalizado\\n\", pd.DataFrame.from_dict(cali_results_raw))\n",
    "print(\"\\nCalifornia Housing DataSet | Normalizado\\n\", pd.DataFrame.from_dict(cali_results_normalized))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
